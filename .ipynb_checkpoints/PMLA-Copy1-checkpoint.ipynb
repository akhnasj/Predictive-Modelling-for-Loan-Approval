{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "de8db61b-b198-4c7e-90ac-c743d03dd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1ab2b541-143d-4ee2-b56e-236f9f275e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "data = pd.read_csv(\"dataset/loan_data.csv\")\n",
    "original_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e05d3982-4986-4160-b23f-fd3477091ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREVIEW: \n",
      "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
      "0  I38PQUQS96   56   85994       50587          520              80   \n",
      "1  HPSK72WA7R   69   50432      124440          458              15   \n",
      "2  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
      "3  V2KKSFM3UN   32   31713       44799          743               0   \n",
      "4  EY08JDHTZP   60   20437        9139          633               8   \n",
      "\n",
      "   NumCreditLines  InterestRate  LoanTerm  DTIRatio    Education  \\\n",
      "0               4         15.23        36      0.44   Bachelor's   \n",
      "1               1          4.81        60      0.68     Master's   \n",
      "2               3         21.17        24      0.31     Master's   \n",
      "3               3          7.07        24      0.23  High School   \n",
      "4               4          6.51        48      0.73   Bachelor's   \n",
      "\n",
      "  EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose  \\\n",
      "0      Full-time      Divorced         Yes           Yes       Other   \n",
      "1      Full-time       Married          No            No       Other   \n",
      "2     Unemployed      Divorced         Yes           Yes        Auto   \n",
      "3      Full-time       Married          No            No    Business   \n",
      "4     Unemployed      Divorced          No           Yes        Auto   \n",
      "\n",
      "  HasCoSigner  Default LoanApprovalStatus  \n",
      "0         Yes        0           Approved  \n",
      "1         Yes        0           Approved  \n",
      "2          No        1           Rejected  \n",
      "3          No        0           Rejected  \n",
      "4          No        0           Rejected  \n",
      "\n",
      "MISSING VALUES: \n",
      "LoanID                0\n",
      "Age                   0\n",
      "Income                0\n",
      "LoanAmount            0\n",
      "CreditScore           0\n",
      "MonthsEmployed        0\n",
      "NumCreditLines        0\n",
      "InterestRate          0\n",
      "LoanTerm              0\n",
      "DTIRatio              0\n",
      "Education             0\n",
      "EmploymentType        0\n",
      "MaritalStatus         0\n",
      "HasMortgage           0\n",
      "HasDependents         0\n",
      "LoanPurpose           0\n",
      "HasCoSigner           0\n",
      "Default               0\n",
      "LoanApprovalStatus    0\n",
      "dtype: int64\n",
      "\n",
      "DATATYPES: \n",
      "LoanID                 object\n",
      "Age                     int64\n",
      "Income                  int64\n",
      "LoanAmount              int64\n",
      "CreditScore             int64\n",
      "MonthsEmployed          int64\n",
      "NumCreditLines          int64\n",
      "InterestRate          float64\n",
      "LoanTerm                int64\n",
      "DTIRatio              float64\n",
      "Education              object\n",
      "EmploymentType         object\n",
      "MaritalStatus          object\n",
      "HasMortgage            object\n",
      "HasDependents          object\n",
      "LoanPurpose            object\n",
      "HasCoSigner            object\n",
      "Default                 int64\n",
      "LoanApprovalStatus     object\n",
      "dtype: object\n",
      "\n",
      "CLASS BALANCE: \n",
      "LoanApprovalStatus\n",
      "Rejected    0.679436\n",
      "Approved    0.320564\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysing the dataset\n",
    "print(f\"DATA PREVIEW: \\n{data.head()}\\n\")\n",
    "print(f\"MISSING VALUES: \\n{data.isnull().sum()}\\n\")\n",
    "print(f\"DATATYPES: \\n{data.dtypes}\\n\")\n",
    "print(f\"CLASS BALANCE: \\n{data[\"LoanApprovalStatus\"].value_counts(normalize = True)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ecd250-0eee-46e0-bbc1-f91484640a7d",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "da04ba17-00a0-408a-b594-14fc0ddbca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner', 'LoanApprovalStatus']\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "cat_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Exclude LoanID from categorical columns before encoding\n",
    "cat_columns = [col for col in cat_columns if col != \"LoanID\"]\n",
    "\n",
    "print(f\"Categorical columns: {cat_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ec97977d-5a2f-4f6b-916f-1c467c4435da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Categorical encoding complete! Updated data preview:\n",
      "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
      "0  I38PQUQS96   56   85994       50587          520              80   \n",
      "1  HPSK72WA7R   69   50432      124440          458              15   \n",
      "2  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
      "3  V2KKSFM3UN   32   31713       44799          743               0   \n",
      "4  EY08JDHTZP   60   20437        9139          633               8   \n",
      "\n",
      "   NumCreditLines  InterestRate  LoanTerm  DTIRatio  ...  HasDependents_Yes  \\\n",
      "0               4         15.23        36      0.44  ...                1.0   \n",
      "1               1          4.81        60      0.68  ...                0.0   \n",
      "2               3         21.17        24      0.31  ...                1.0   \n",
      "3               3          7.07        24      0.23  ...                0.0   \n",
      "4               4          6.51        48      0.73  ...                1.0   \n",
      "\n",
      "   LoanPurpose_Auto  LoanPurpose_Business  LoanPurpose_Education  \\\n",
      "0               0.0                   0.0                    0.0   \n",
      "1               0.0                   0.0                    0.0   \n",
      "2               1.0                   0.0                    0.0   \n",
      "3               0.0                   1.0                    0.0   \n",
      "4               1.0                   0.0                    0.0   \n",
      "\n",
      "   LoanPurpose_Home  LoanPurpose_Other  HasCoSigner_No  HasCoSigner_Yes  \\\n",
      "0               0.0                1.0             0.0              1.0   \n",
      "1               0.0                1.0             0.0              1.0   \n",
      "2               0.0                0.0             1.0              0.0   \n",
      "3               0.0                0.0             1.0              0.0   \n",
      "4               0.0                0.0             1.0              0.0   \n",
      "\n",
      "   LoanApprovalStatus_Approved  LoanApprovalStatus_Rejected  \n",
      "0                          1.0                          0.0  \n",
      "1                          1.0                          0.0  \n",
      "2                          0.0                          1.0  \n",
      "3                          0.0                          1.0  \n",
      "4                          0.0                          1.0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding for categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_cat_features = encoder.fit_transform(data[cat_columns])\n",
    "\n",
    "# Convert encoded categorical features into a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_cat_features, columns=encoder.get_feature_names_out(cat_columns))\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded data\n",
    "data = data.drop(columns=cat_columns).reset_index(drop=True)\n",
    "data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "print(f\"âœ… Categorical encoding complete! Updated data preview:\\n{data.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b09b6-8de9-44bc-8870-1ceda8ef3c2c",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "16eefc3c-90c1-4b56-a8b1-7d260e0047ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns before scaling: ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio', 'Default']\n",
      "âœ… Feature scaling complete! Updated data preview:\n",
      "       LoanID       Age    Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
      "0  I38PQUQS96  0.833990  0.089693   -1.086833    -0.341492        0.590533   \n",
      "1  HPSK72WA7R  1.701221 -0.823021   -0.044309    -0.731666       -1.285731   \n",
      "2  C1OZ6DPJ8Y  0.166888  0.043854    0.022715    -0.775718       -0.968209   \n",
      "3  V2KKSFM3UN -0.767053 -1.303452   -1.168538     1.061875       -1.718715   \n",
      "4  EY08JDHTZP  1.100830 -1.592855   -1.671921     0.369631       -1.487790   \n",
      "\n",
      "   NumCreditLines  InterestRate  LoanTerm  DTIRatio  ...  HasDependents_Yes  \\\n",
      "0        1.341937      0.261771 -0.001526 -0.260753  ...                1.0   \n",
      "1       -1.343791     -1.308350  1.412793  0.778585  ...                0.0   \n",
      "2        0.446694      1.156831 -0.708685 -0.823728  ...                1.0   \n",
      "3        0.446694     -0.967805 -0.708685 -1.170174  ...                0.0   \n",
      "4        1.341937     -1.052188  0.705634  0.995114  ...                1.0   \n",
      "\n",
      "   LoanPurpose_Auto  LoanPurpose_Business  LoanPurpose_Education  \\\n",
      "0               0.0                   0.0                    0.0   \n",
      "1               0.0                   0.0                    0.0   \n",
      "2               1.0                   0.0                    0.0   \n",
      "3               0.0                   1.0                    0.0   \n",
      "4               1.0                   0.0                    0.0   \n",
      "\n",
      "   LoanPurpose_Home  LoanPurpose_Other  HasCoSigner_No  HasCoSigner_Yes  \\\n",
      "0               0.0                1.0             0.0              1.0   \n",
      "1               0.0                1.0             0.0              1.0   \n",
      "2               0.0                0.0             1.0              0.0   \n",
      "3               0.0                0.0             1.0              0.0   \n",
      "4               0.0                0.0             1.0              0.0   \n",
      "\n",
      "   LoanApprovalStatus_Approved  LoanApprovalStatus_Rejected  \n",
      "0                          1.0                          0.0  \n",
      "1                          1.0                          0.0  \n",
      "2                          0.0                          1.0  \n",
      "3                          0.0                          1.0  \n",
      "4                          0.0                          1.0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical columns\n",
    "num_columns = original_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(f\"Numerical Columns before scaling: {num_columns}\")\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply StandardScaler only to numerical columns\n",
    "data[num_columns] = scaler.fit_transform(data[num_columns])\n",
    "\n",
    "print(\"âœ… Feature scaling complete! Updated data preview:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2e38d-0a72-402f-9b53-37e156d5cfd7",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c7bf0e18-e992-40ec-8021-412db10f26ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data splitting complete! Training samples: 178742, Validation samples: 38302, Test samples: 38303\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ Step 7: Drop LoanID (if it exists)\n",
    "if \"LoanID\" in data.columns:\n",
    "    data = data.drop(columns=[\"LoanID\"])\n",
    "\n",
    "# ðŸš€ Step 8: Extract Target Column\n",
    "y = data[\"LoanApprovalStatus_Approved\"]  # Use the encoded column\n",
    "X = data.drop(columns=[\"LoanApprovalStatus_Approved\", \"LoanApprovalStatus_Rejected\"])  # Drop both encoded target columns\n",
    "\n",
    "# ðŸš€ Step 9: Split into Train, Validation, and Test Sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"âœ… Data splitting complete! Training samples: {X_train.shape[0]}, Validation samples: {X_val.shape[0]}, Test samples: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "91196fef-d7c5-45df-991d-7352d7024435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\akhna\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\akhna\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\akhna\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b6d5b37e-739e-4a3f-91b3-98e5542c5df7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[238], line 24\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# ðŸš€ Step 2: Train the XGBoost Model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\n\u001b[0;32m     14\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Since it's a binary classification problem\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Helps prevent overfitting\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train, eval_set\u001b[38;5;241m=\u001b[39m[(X_val_scaled, y_val)], early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ðŸš€ Step 3: Model Evaluation\u001b[39;00m\n\u001b[0;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: XGBClassifier.fit() got an unexpected keyword argument 'early_stopping_rounds'"
     ]
    }
   ],
   "source": [
    "# XGBoost Model\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ðŸš€ Step 1: Feature Scaling (XGBoost handles it well, but for consistency)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ðŸš€ Step 2: Train the XGBoost Model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",  # Since it's a binary classification problem\n",
    "    eval_metric=\"logloss\",  # Helps prevent overfitting\n",
    "    learning_rate=0.1, \n",
    "    n_estimators=100, \n",
    "    max_depth=5,\n",
    "    subsample=0.8, \n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_scaled, y_train, eval_set=[(X_val_scaled, y_val)], early_stopping_rounds=10, verbose=True)\n",
    "\n",
    "# ðŸš€ Step 3: Model Evaluation\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# ðŸš€ Step 4: Print Performance Metrics\n",
    "print(f\"âœ… Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"âœ… Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"âœ… Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"âœ… F1 Score: {f1_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "825e658c-5ad1-45f8-be2c-c436fdce71e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKHNA\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKHNA\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [01:35:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance:\n",
      "\n",
      "Logistic Regression:\n",
      "Accuracy: 0.9422\n",
      "Precision: 0.9242\n",
      "Recall: 0.8915\n",
      "F1 Score: 0.9075\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy: 0.9986\n",
      "Precision: 0.9976\n",
      "Recall: 0.9978\n",
      "F1 Score: 0.9977\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9982\n",
      "Precision: 0.9990\n",
      "Recall: 0.9953\n",
      "F1 Score: 0.9971\n",
      "\n",
      "AdaBoost:\n",
      "Accuracy: 0.9628\n",
      "Precision: 0.9290\n",
      "Recall: 0.9562\n",
      "F1 Score: 0.9424\n",
      "\n",
      "XGBoost:\n",
      "Accuracy: 0.9993\n",
      "Precision: 0.9987\n",
      "Recall: 0.9990\n",
      "F1 Score: 0.9988\n"
     ]
    }
   ],
   "source": [
    "### Training various models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_split=50, min_samples_leaf=25),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=50, min_samples_leaf=25),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"\\nModel Performance:\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bd143b4e-ec52-4dac-a200-3c2a8891a42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKHNA\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKHNA\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKHNA\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKHNA\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKHNA\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\AKHNA\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "\n",
      "ðŸ“Š Model Performance:\n",
      "\n",
      "ðŸ”¹ Logistic Regression:\n",
      "Test Accuracy: 0.9422\n",
      "CV Accuracy: 0.9422\n",
      "Precision: 0.9242\n",
      "Recall: 0.8915\n",
      "F1 Score: 0.9075\n",
      "\n",
      "ðŸ”¹ Decision Tree:\n",
      "Test Accuracy: 0.9938\n",
      "CV Accuracy: 0.9943\n",
      "Precision: 0.9891\n",
      "Recall: 0.9913\n",
      "F1 Score: 0.9902\n",
      "\n",
      "ðŸ”¹ Random Forest:\n",
      "Test Accuracy: 0.9802\n",
      "CV Accuracy: 0.9817\n",
      "Precision: 0.9993\n",
      "Recall: 0.9383\n",
      "F1 Score: 0.9679\n",
      "\n",
      "ðŸ”¹ AdaBoost:\n",
      "Test Accuracy: 0.9610\n",
      "CV Accuracy: 0.9599\n",
      "Precision: 0.9184\n",
      "Recall: 0.9630\n",
      "F1 Score: 0.9402\n",
      "\n",
      "ðŸ”¹ XGBoost:\n",
      "Test Accuracy: 0.9983\n",
      "CV Accuracy: 0.9984\n",
      "Precision: 0.9972\n",
      "Recall: 0.9975\n",
      "F1 Score: 0.9974\n",
      "\n",
      "ðŸ“Œ Feature Importances:\n",
      "\n",
      "ðŸ”¹ Decision Tree:\n",
      "LoanPurpose_Other: 0.5378\n",
      "DTIRatio: 0.2178\n",
      "CreditScore: 0.1197\n",
      "LoanPurpose_Education: 0.0350\n",
      "LoanPurpose_Auto: 0.0329\n",
      "LoanPurpose_Business: 0.0155\n",
      "LoanPurpose_Home: 0.0133\n",
      "LoanAmount: 0.0087\n",
      "Default: 0.0070\n",
      "LoanTerm: 0.0061\n",
      "\n",
      "ðŸ”¹ Random Forest:\n",
      "LoanPurpose_Other: 0.4856\n",
      "CreditScore: 0.1554\n",
      "DTIRatio: 0.1337\n",
      "LoanPurpose_Home: 0.0845\n",
      "LoanPurpose_Business: 0.0577\n",
      "LoanPurpose_Education: 0.0383\n",
      "LoanPurpose_Auto: 0.0343\n",
      "LoanAmount: 0.0028\n",
      "Default: 0.0022\n",
      "Income: 0.0019\n",
      "\n",
      "ðŸ”¹ AdaBoost:\n",
      "CreditScore: 0.3800\n",
      "DTIRatio: 0.3500\n",
      "LoanPurpose_Home: 0.1000\n",
      "LoanPurpose_Education: 0.0800\n",
      "LoanPurpose_Other: 0.0500\n",
      "LoanPurpose_Business: 0.0400\n",
      "Age: 0.0000\n",
      "Income: 0.0000\n",
      "LoanAmount: 0.0000\n",
      "MonthsEmployed: 0.0000\n",
      "\n",
      "ðŸ”¹ XGBoost:\n",
      "LoanPurpose_Other: 0.6916\n",
      "DTIRatio: 0.0845\n",
      "CreditScore: 0.0765\n",
      "LoanPurpose_Auto: 0.0375\n",
      "LoanPurpose_Education: 0.0343\n",
      "LoanPurpose_Home: 0.0229\n",
      "LoanPurpose_Business: 0.0216\n",
      "Default: 0.0087\n",
      "LoanTerm: 0.0060\n",
      "LoanAmount: 0.0058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define models with tuned hyperparameters\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, penalty='l2'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_split=50, min_samples_leaf=25),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=8, min_samples_split=100, min_samples_leaf=50),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, learning_rate=0.1),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, subsample=0.7, colsample_bytree=0.7, reg_lambda=10, reg_alpha=2, eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    \n",
    "    # Fit model on full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\n",
    "        \"Test Accuracy\": accuracy,\n",
    "        \"CV Accuracy\": cv_scores.mean(),\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"\\nðŸ“Š Model Performance:\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"\\nðŸ”¹ {model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Feature Importance for Tree-Based Models\n",
    "print(\"\\nðŸ“Œ Feature Importances:\")\n",
    "for name, model in models.items():\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importance = model.feature_importances_\n",
    "        top_features = sorted(zip(X_train.columns, importance), key=lambda x: x[1], reverse=True)[:10]  # Top 10 features\n",
    "        print(f\"\\nðŸ”¹ {name}:\")\n",
    "        for feature, score in top_features:\n",
    "            print(f\"{feature}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152c35c-dc01-426c-a7e4-d0a2f4c4641d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
