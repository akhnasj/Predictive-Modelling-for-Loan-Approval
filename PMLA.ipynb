{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09da753a-f63b-44cb-be9a-de8d6eab8105",
   "metadata": {},
   "source": [
    "## Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "de8db61b-b198-4c7e-90ac-c743d03dd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "1ab2b541-143d-4ee2-b56e-236f9f275e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "data = pd.read_csv(\"dataset/loan_data.csv\")\n",
    "original_data = data.copy()\n",
    "data[\"Default\"] = data[\"Default\"].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e05d3982-4986-4160-b23f-fd3477091ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA PREVIEW: \n",
      "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
      "0  I38PQUQS96   56   85994       50587          520              80   \n",
      "1  HPSK72WA7R   69   50432      124440          458              15   \n",
      "2  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
      "3  V2KKSFM3UN   32   31713       44799          743               0   \n",
      "4  EY08JDHTZP   60   20437        9139          633               8   \n",
      "\n",
      "   NumCreditLines  InterestRate  LoanTerm  DTIRatio    Education  \\\n",
      "0               4         15.23        36      0.44   Bachelor's   \n",
      "1               1          4.81        60      0.68     Master's   \n",
      "2               3         21.17        24      0.31     Master's   \n",
      "3               3          7.07        24      0.23  High School   \n",
      "4               4          6.51        48      0.73   Bachelor's   \n",
      "\n",
      "  EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose  \\\n",
      "0      Full-time      Divorced         Yes           Yes       Other   \n",
      "1      Full-time       Married          No            No       Other   \n",
      "2     Unemployed      Divorced         Yes           Yes        Auto   \n",
      "3      Full-time       Married          No            No    Business   \n",
      "4     Unemployed      Divorced          No           Yes        Auto   \n",
      "\n",
      "  HasCoSigner  Default LoanApprovalStatus  \n",
      "0         Yes    False           Approved  \n",
      "1         Yes    False           Approved  \n",
      "2          No     True           Rejected  \n",
      "3          No    False           Rejected  \n",
      "4          No    False           Rejected  \n",
      "\n",
      "MISSING VALUES: \n",
      "LoanID                0\n",
      "Age                   0\n",
      "Income                0\n",
      "LoanAmount            0\n",
      "CreditScore           0\n",
      "MonthsEmployed        0\n",
      "NumCreditLines        0\n",
      "InterestRate          0\n",
      "LoanTerm              0\n",
      "DTIRatio              0\n",
      "Education             0\n",
      "EmploymentType        0\n",
      "MaritalStatus         0\n",
      "HasMortgage           0\n",
      "HasDependents         0\n",
      "LoanPurpose           0\n",
      "HasCoSigner           0\n",
      "Default               0\n",
      "LoanApprovalStatus    0\n",
      "dtype: int64\n",
      "\n",
      "DATATYPES: \n",
      "LoanID                 object\n",
      "Age                     int64\n",
      "Income                  int64\n",
      "LoanAmount              int64\n",
      "CreditScore             int64\n",
      "MonthsEmployed          int64\n",
      "NumCreditLines          int64\n",
      "InterestRate          float64\n",
      "LoanTerm                int64\n",
      "DTIRatio              float64\n",
      "Education              object\n",
      "EmploymentType         object\n",
      "MaritalStatus          object\n",
      "HasMortgage            object\n",
      "HasDependents          object\n",
      "LoanPurpose            object\n",
      "HasCoSigner            object\n",
      "Default                  bool\n",
      "LoanApprovalStatus     object\n",
      "dtype: object\n",
      "\n",
      "CLASS BALANCE: \n",
      "LoanApprovalStatus\n",
      "Rejected    0.679436\n",
      "Approved    0.320564\n",
      "Name: proportion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysing the dataset\n",
    "print(f\"DATA PREVIEW: \\n{data.head()}\\n\")\n",
    "\n",
    "# Handling Missing Values\n",
    "print(f\"MISSING VALUES: \\n{data.isnull().sum()}\\n\")\n",
    "print(f\"DATATYPES: \\n{data.dtypes}\\n\")\n",
    "print(f\"CLASS BALANCE: \\n{data[\"LoanApprovalStatus\"].value_counts(normalize = True)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ecd250-0eee-46e0-bbc1-f91484640a7d",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "da04ba17-00a0-408a-b594-14fc0ddbca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner', 'LoanApprovalStatus', 'Default']\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns (excluding numerical ones)\n",
    "cat_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Exclude LoanID from categorical columns before encoding\n",
    "cat_columns = [col for col in cat_columns if col != \"LoanID\"]\n",
    "\n",
    "# Manually add 'Default' as a categorical column\n",
    "cat_columns.append(\"Default\")\n",
    "\n",
    "print(f\"Categorical columns: {cat_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ec97977d-5a2f-4f6b-916f-1c467c4435da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Categorical encoding complete! Updated data preview:\n",
      "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
      "0  I38PQUQS96   56   85994       50587          520              80   \n",
      "1  HPSK72WA7R   69   50432      124440          458              15   \n",
      "2  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
      "3  V2KKSFM3UN   32   31713       44799          743               0   \n",
      "4  EY08JDHTZP   60   20437        9139          633               8   \n",
      "\n",
      "   NumCreditLines  InterestRate  LoanTerm  DTIRatio  ...  \\\n",
      "0               4         15.23        36      0.44  ...   \n",
      "1               1          4.81        60      0.68  ...   \n",
      "2               3         21.17        24      0.31  ...   \n",
      "3               3          7.07        24      0.23  ...   \n",
      "4               4          6.51        48      0.73  ...   \n",
      "\n",
      "   LoanPurpose_Business  LoanPurpose_Education  LoanPurpose_Home  \\\n",
      "0                   0.0                    0.0               0.0   \n",
      "1                   0.0                    0.0               0.0   \n",
      "2                   0.0                    0.0               0.0   \n",
      "3                   1.0                    0.0               0.0   \n",
      "4                   0.0                    0.0               0.0   \n",
      "\n",
      "   LoanPurpose_Other  HasCoSigner_No  HasCoSigner_Yes  \\\n",
      "0                1.0             0.0              1.0   \n",
      "1                1.0             0.0              1.0   \n",
      "2                0.0             1.0              0.0   \n",
      "3                0.0             1.0              0.0   \n",
      "4                0.0             1.0              0.0   \n",
      "\n",
      "   LoanApprovalStatus_Approved  LoanApprovalStatus_Rejected  Default_False  \\\n",
      "0                          1.0                          0.0            1.0   \n",
      "1                          1.0                          0.0            1.0   \n",
      "2                          0.0                          1.0            0.0   \n",
      "3                          0.0                          1.0            1.0   \n",
      "4                          0.0                          1.0            1.0   \n",
      "\n",
      "   Default_True  \n",
      "0           0.0  \n",
      "1           0.0  \n",
      "2           1.0  \n",
      "3           0.0  \n",
      "4           0.0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check if any categorical columns exist before encoding\n",
    "if not cat_columns:\n",
    "    print(\"⚠️ No categorical columns found for encoding!\")\n",
    "else:\n",
    "    # One-Hot Encoding for categorical features\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    encoded_cat_features = encoder.fit_transform(data[cat_columns])\n",
    "\n",
    "    # Convert encoded categorical features into a DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded_cat_features, columns=encoder.get_feature_names_out(cat_columns))\n",
    "\n",
    "    # Drop original categorical columns and concatenate encoded data\n",
    "    data = data.drop(columns=cat_columns).reset_index(drop=True)\n",
    "    data = pd.concat([data, encoded_df], axis=1)\n",
    "\n",
    "    print(f\"✅ Categorical encoding complete! Updated data preview:\\n{data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "16eefc3c-90c1-4b56-a8b1-7d260e0047ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns before scaling: ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical columns\n",
    "num_columns = original_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Ensure only existing numerical columns are used for scaling\n",
    "num_columns = [col for col in num_columns if col in data.columns]\n",
    "\n",
    "print(f\"Numerical Columns before scaling: {num_columns}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2e38d-0a72-402f-9b53-37e156d5cfd7",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c7bf0e18-e992-40ec-8021-412db10f26ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data Split | Train: 178742, Val: 38302, Test: 38303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 🚀 Step 7: Drop LoanID (if it exists)\n",
    "if \"LoanID\" in data.columns:\n",
    "    data = data.drop(columns=[\"LoanID\"])\n",
    "    \n",
    "\n",
    "# 🔹 Extract Target Column\n",
    "y = data[\"LoanApprovalStatus_Approved\"].astype(int)  # Convert target to numeric\n",
    "X = data.drop(columns=[\"LoanApprovalStatus_Approved\", \"LoanApprovalStatus_Rejected\"], errors='ignore')\n",
    "X = X.drop(columns=[\"LoanID\"], errors='ignore')  # Remove LoanID if it exists\n",
    "\n",
    "# 🚀 Split data BEFORE applying SMOTE\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "\n",
    "print(f\"✅ Data Split | Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "41b3eb11-0a40-473f-b1a4-307c93ded428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoanApprovalStatus_Approved\n",
      "0    173492\n",
      "1     81855\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be349b3-3be5-46d7-a436-bc3401239ab7",
   "metadata": {},
   "source": [
    "## SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "affd7a25-a8ea-419f-870f-31aff2f70202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 🚀 Apply SMOTE only to the training data\n",
    "smote = SMOTE(sampling_strategy=0.7, random_state=42)  # Adjust ratio if needed\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# ✅ Convert back to DataFrame (SMOTE may return NumPy arrays)\n",
    "X_train_smote = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "y_train_smote = pd.Series(y_train_smote)  # Ensure target remains a Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "feab4d56-290a-4cc4-95d1-cc40c3d0d566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before SMOTE: 178742 samples\n",
      "Dataset size after SMOTE: 206454 samples\n",
      "🔍 New samples added: 27712\n",
      "\n",
      "\n",
      "🔴 Before SMOTE:\n",
      "                               Count  Percentage\n",
      "LoanApprovalStatus_Approved                    \n",
      "0                            121444    67.94374\n",
      "1                             57298    32.05626\n",
      "\n",
      "✅ After SMOTE:\n",
      "                               Count  Percentage\n",
      "LoanApprovalStatus_Approved                    \n",
      "0                            121444   58.823757\n",
      "1                             85010   41.176243\n"
     ]
    }
   ],
   "source": [
    "# ✅ Correct Dataset Size Comparison\n",
    "print(f\"Dataset size before SMOTE: {X_train.shape[0]} samples\")\n",
    "print(f\"Dataset size after SMOTE: {X_train_smote.shape[0]} samples\")\n",
    "print(f\"🔍 New samples added: {X_train_smote.shape[0] - X_train.shape[0]}\")\n",
    "\n",
    "# ✅ Class Distribution Before and After SMOTE\n",
    "before_smote = pd.DataFrame({\n",
    "    \"Count\": y_train.value_counts(),\n",
    "    \"Percentage\": y_train.value_counts(normalize=True) * 100\n",
    "})\n",
    "\n",
    "after_smote = pd.DataFrame({\n",
    "    \"Count\": y_train_smote.value_counts(),\n",
    "    \"Percentage\": y_train_smote.value_counts(normalize=True) * 100\n",
    "})\n",
    "\n",
    "print(\"\\n\\n🔴 Before SMOTE:\\n\", before_smote)\n",
    "print(\"\\n✅ After SMOTE:\\n\", after_smote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b09b6-8de9-44bc-8870-1ceda8ef3c2c",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "61eee6b2-a446-4777-8dda-762bb95fd545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature Scaling Applied Successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 🚀 Step 1: Identify Numerical Columns\n",
    "num_cols = X_train_smote.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# 🚀 Step 2: Initialize StandardScaler and Fit on Training Data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_smote[num_cols])  # ✅ Fit only on training data\n",
    "\n",
    "# 🚀 Step 3: Create Copies for Scaling\n",
    "X_train_scaled = X_train_smote.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# 🚀 Step 4: Apply Standardization (Only on Numerical Columns)\n",
    "X_train_scaled[num_cols] = scaler.transform(X_train_smote[num_cols])\n",
    "X_val_scaled[num_cols] = scaler.transform(X_val[num_cols])\n",
    "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "print(\"✅ Feature Scaling Applied Successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c5f24-0273-4877-a94b-53e27a6fd413",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "b6d5b37e-739e-4a3f-91b3-98e5542c5df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Early stopping triggered at 11 iterations.\n",
      "✅ Model trained with best iteration: 11\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "# 🚀 Check class balance to adjust `scale_pos_weight`\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "scale_pos_weight = counts[0] / counts[1] if counts[1] > 0 else 1  # Prevent division by zero\n",
    "\n",
    "# 🚀 Optimized Hyperparameters\n",
    "best_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"aucpr\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_depth\": 2,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.65,\n",
    "    \"reg_lambda\": 100,\n",
    "    \"reg_alpha\": 50,\n",
    "    \"gamma\": 0.5,\n",
    "    \"n_jobs\": 4,\n",
    "    \"scale_pos_weight\": scale_pos_weight\n",
    "}\n",
    "\n",
    "# 🚀 Train XGBClassifier (Manually Implementing Early Stopping)\n",
    "xgb_model = xgb.XGBClassifier(**best_params, n_estimators=50)  # ✅ No early stopping argument\n",
    "\n",
    "best_iteration = 0\n",
    "best_score = float(\"-inf\")\n",
    "patience = 20  # Stop if no improvement for 20 rounds\n",
    "wait = 0\n",
    "\n",
    "for i in range(1, 51):  # Train up to 50 boosting rounds\n",
    "    xgb_model.n_estimators = i\n",
    "    xgb_model.fit(X_train_scaled, y_train_smote)  # Train with the updated estimator count\n",
    "    \n",
    "    # Validate the model\n",
    "    y_val_pred = xgb_model.predict(X_val_scaled)\n",
    "    score = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Check improvement\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_iteration = i\n",
    "        wait = 0  # Reset patience counter\n",
    "    else:\n",
    "        wait += 1  # Increase patience counter\n",
    "    \n",
    "    if wait >= patience:\n",
    "        print(f\"✅ Early stopping triggered at {best_iteration} iterations.\")\n",
    "        break  # Stop training\n",
    "\n",
    "# Set the final model to best iteration\n",
    "xgb_model.n_estimators = best_iteration\n",
    "xgb_model.fit(X_train_scaled, y_train_smote)  # Retrain on best iteration\n",
    "\n",
    "print(f\"✅ Model trained with best iteration: {best_iteration}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b323b1ce-d333-43b8-a2ef-6114b1c6c354",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "37bf24a8-39df-4c30-b018-51d65bd2bbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Evaluation on Test Data:\n",
      "   Accuracy: 0.9526\n",
      "   Precision: 0.8966\n",
      "   Recall: 0.9634\n",
      "   F1 Score: 0.9288\n",
      "   ROC AUC: 0.9913\n",
      "⚡ Cross-validation Accuracy: 0.9659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# 🚀 Make Predictions\n",
    "y_pred_proba = xgb_model.predict_proba(X_test_scaled)[:, 1]  # Get probability scores\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)  # Convert to 0/1 labels\n",
    "\n",
    "# 🚀 Evaluate Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)  # AUC based on probabilities\n",
    "\n",
    "print(f\"✅ Model Evaluation on Test Data:\")\n",
    "print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "print(f\"   Precision: {precision:.4f}\")\n",
    "print(f\"   Recall: {recall:.4f}\")\n",
    "print(f\"   F1 Score: {f1:.4f}\")\n",
    "print(f\"   ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# 🚀 Cross-validation (On Original Training Data, Not SMOTE)\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(f\"⚡ Cross-validation Accuracy: {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1609f6c5-35c9-423c-b583-80afa583f6b1",
   "metadata": {},
   "source": [
    "## Save & Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2a1e22d6-8245-4767-8ac6-6d39ff4f6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained and saved successfully!\n",
      "✅ Scaler saved successfully!\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.65, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='aucpr', feature_types=None,\n",
      "              feature_weights=None, gamma=0.5, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=2,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=11,\n",
      "              n_jobs=4, num_parallel_tree=None, ...)\n",
      "StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(xgb_model, \"loan_model.pkl\")\n",
    "print(\"✅ Model trained and saved successfully!\")\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"✅ Scaler saved successfully!\")\n",
    "\n",
    "# Load the model and scaler for verification\n",
    "model = joblib.load(\"loan_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "print(model)  # Should print XGBClassifier with correct parameters\n",
    "print(scaler)  # Should print StandardScaler() with fitted parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c924a563-bc4b-42e0-9d7e-1ea0e7da3f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Sample: [[65.24098568 -1.99613171 -1.79664837 -3.72948067 -1.76052988 -2.22871297\n",
      "  -2.08055019 -2.17402394 -2.15945819 -0.59282102 -0.59352378 -0.58827461\n",
      "  -0.58849171 -0.5890156  -0.59328474 -0.58918022 -0.59130568 -0.72212275\n",
      "  -0.72326244 -0.72501753 -1.02617139 -1.02059339 -1.02533348 -1.02102306\n",
      "  -0.48887748 -0.48027251 -0.49509993 -0.472367   -0.60267452 -1.02247367\n",
      "  -1.02426523 -2.84149008 -0.36669351]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get feature names from the training data\n",
    "feature_names = X_train_smote.columns  # Ensure these match the original dataset\n",
    "\n",
    "# Convert sample_data to a DataFrame with correct column names\n",
    "sample_data_df = pd.DataFrame(sample_data, columns=feature_names)\n",
    "\n",
    "# Transform the sample data\n",
    "scaled_sample = scaler.transform(sample_data_df)\n",
    "\n",
    "print(\"Scaled Sample:\", scaled_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "da9b74db-0abe-4a92-a395-e6e9ac40b332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.preprocessing._data.StandardScaler'>\n"
     ]
    }
   ],
   "source": [
    "print(type(scaler))  # Should print <class 'sklearn.preprocessing._data.StandardScaler'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "825e658c-5ad1-45f8-be2c-c436fdce71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Training various models\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# # Define models\n",
    "# models = {\n",
    "#     \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "#     \"Decision Tree\": DecisionTreeClassifier(max_depth=10, min_samples_split=50, min_samples_leaf=25),\n",
    "#     \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=50, min_samples_leaf=25),\n",
    "#     \"AdaBoost\": AdaBoostClassifier(),\n",
    "#     \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "# }\n",
    "\n",
    "# # Train and evaluate models\n",
    "# results = {}\n",
    "# for name, model in models.items():\n",
    "#     print(f\"Training {name}...\")\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     # Compute metrics\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred)\n",
    "#     recall = recall_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "#     results[name] = {\n",
    "#         \"Accuracy\": accuracy,\n",
    "#         \"Precision\": precision,\n",
    "#         \"Recall\": recall,\n",
    "#         \"F1 Score\": f1\n",
    "#     }\n",
    "\n",
    "# # Print results\n",
    "# print(\"\\nModel Performance:\")\n",
    "# for model, metrics in results.items():\n",
    "#     print(f\"\\n{model}:\")\n",
    "#     for metric, value in metrics.items():\n",
    "#         print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e909b1cf-4691-4c49-9f0c-7bcc0b15263c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATATYPES: \n",
      "Age                               int64\n",
      "Income                            int64\n",
      "LoanAmount                        int64\n",
      "CreditScore                       int64\n",
      "MonthsEmployed                    int64\n",
      "NumCreditLines                    int64\n",
      "InterestRate                    float64\n",
      "LoanTerm                          int64\n",
      "DTIRatio                        float64\n",
      "Education_Bachelor's            float64\n",
      "Education_High School           float64\n",
      "Education_Master's              float64\n",
      "Education_PhD                   float64\n",
      "EmploymentType_Full-time        float64\n",
      "EmploymentType_Part-time        float64\n",
      "EmploymentType_Self-employed    float64\n",
      "EmploymentType_Unemployed       float64\n",
      "MaritalStatus_Divorced          float64\n",
      "MaritalStatus_Married           float64\n",
      "MaritalStatus_Single            float64\n",
      "HasMortgage_No                  float64\n",
      "HasMortgage_Yes                 float64\n",
      "HasDependents_No                float64\n",
      "HasDependents_Yes               float64\n",
      "LoanPurpose_Auto                float64\n",
      "LoanPurpose_Business            float64\n",
      "LoanPurpose_Education           float64\n",
      "LoanPurpose_Home                float64\n",
      "LoanPurpose_Other               float64\n",
      "HasCoSigner_No                  float64\n",
      "HasCoSigner_Yes                 float64\n",
      "LoanApprovalStatus_Approved     float64\n",
      "LoanApprovalStatus_Rejected     float64\n",
      "Default_False                   float64\n",
      "Default_True                    float64\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"DATATYPES: \\n{data.dtypes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b64b531-b8b6-4192-b17d-f7805732e409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed',\n",
      "       'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio',\n",
      "       'Education_Bachelor's', 'Education_High School', 'Education_Master's',\n",
      "       'Education_PhD', 'EmploymentType_Full-time', 'EmploymentType_Part-time',\n",
      "       'EmploymentType_Self-employed', 'EmploymentType_Unemployed',\n",
      "       'MaritalStatus_Divorced', 'MaritalStatus_Married',\n",
      "       'MaritalStatus_Single', 'HasMortgage_No', 'HasMortgage_Yes',\n",
      "       'HasDependents_No', 'HasDependents_Yes', 'LoanPurpose_Auto',\n",
      "       'LoanPurpose_Business', 'LoanPurpose_Education', 'LoanPurpose_Home',\n",
      "       'LoanPurpose_Other', 'HasCoSigner_No', 'HasCoSigner_Yes',\n",
      "       'Default_False', 'Default_True'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "552baa89-d94a-412b-bdb3-c5c21e36d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Original Sample Loan Application Data (Before Processing):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DebtToIncomeRatio</th>\n",
       "      <th>EmploymentYears</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmploymentType</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>HasMortgage</th>\n",
       "      <th>HasDependents</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>HasCoSigner</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>300000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>Single</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Business</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantIncome  LoanAmount  CreditScore  DebtToIncomeRatio  \\\n",
       "0             2000      300000           20                0.6   \n",
       "\n",
       "   EmploymentYears    Education EmploymentType MaritalStatus HasMortgage  \\\n",
       "0                0  High School     Unemployed        Single          No   \n",
       "\n",
       "  HasDependents LoanPurpose HasCoSigner Default  \n",
       "0            No    Business          No    True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Processed Sample Data (After Encoding):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>DebtToIncomeRatio</th>\n",
       "      <th>EmploymentYears</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>300000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantIncome  LoanAmount  CreditScore  DebtToIncomeRatio  \\\n",
       "0             2000      300000           20                0.6   \n",
       "\n",
       "   EmploymentYears  \n",
       "0                0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature Scaling Applied!\n",
      "\n",
      "🔴 Model Prediction: Loan is **Approved**\n"
     ]
    }
   ],
   "source": [
    "# 📌 Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 📌 Load Trained Model\n",
    "model_filename = \"loan_model.pkl\"  # Change this if filename differs\n",
    "with open(model_filename, \"rb\") as file:\n",
    "    loan_model = pickle.load(file)\n",
    "\n",
    "# 📌 Define Original Dataset Columns (Before Encoding)\n",
    "original_columns = [\n",
    "    \"ApplicantIncome\", \"LoanAmount\", \"CreditScore\", \"DebtToIncomeRatio\", \"EmploymentYears\",\n",
    "    \"Education\", \"EmploymentType\", \"MaritalStatus\", \"HasMortgage\", \"HasDependents\",\n",
    "    \"LoanPurpose\", \"HasCoSigner\", \"Default\"\n",
    "]\n",
    "\n",
    "# 📌 Create Sample Data That Should Be Rejected (Original Column Names)\n",
    "rejected_loan_sample = pd.DataFrame([{\n",
    "    \"ApplicantIncome\": 2000,        # Low income\n",
    "    \"LoanAmount\": 300000,              # High loan amount relative to income\n",
    "    \"CreditScore\": 20,             # Poor credit score\n",
    "    \"DebtToIncomeRatio\": 0.6,       # High debt-to-income ratio\n",
    "    \"EmploymentYears\": 0,           # No work experience\n",
    "    \"Education\": \"High School\",     # Low education level\n",
    "    \"EmploymentType\": \"Unemployed\", # No job\n",
    "    \"MaritalStatus\": \"Single\",      # No financial support from spouse\n",
    "    \"HasMortgage\": \"No\",            # No assets as collateral\n",
    "    \"HasDependents\": \"No\",          # No dependents (neutral factor)\n",
    "    \"LoanPurpose\": \"Business\",         # Generic loan purpose\n",
    "    \"HasCoSigner\": \"No\",            # No co-signer to support repayment\n",
    "    \"Default\": \"True\"               # High risk case\n",
    "}])\n",
    "\n",
    "print(\"🚀 Original Sample Loan Application Data (Before Processing):\")\n",
    "display(rejected_loan_sample)\n",
    "\n",
    "# ----------------- 🔹 DATA PROCESSING 🔹 -----------------\n",
    "# 📌 Convert Categorical Columns Using One-Hot Encoding\n",
    "categorical_cols = [\"Education\", \"EmploymentType\", \"MaritalStatus\", \"HasMortgage\", \"HasDependents\", \"LoanPurpose\", \"HasCoSigner\", \"Default\"]\n",
    "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)  # Drop first to avoid dummy variable trap\n",
    "encoded_features = encoder.fit_transform(rejected_loan_sample[categorical_cols])\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "\n",
    "# 📌 Convert Encoded Features to DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names)\n",
    "\n",
    "# 📌 Merge Encoded Data with Numeric Features\n",
    "numeric_cols = [\"ApplicantIncome\", \"LoanAmount\", \"CreditScore\", \"DebtToIncomeRatio\", \"EmploymentYears\"]\n",
    "processed_loan_sample = pd.concat([rejected_loan_sample[numeric_cols].reset_index(drop=True), encoded_df], axis=1)\n",
    "\n",
    "print(\"🔹 Processed Sample Data (After Encoding):\")\n",
    "display(processed_loan_sample)\n",
    "\n",
    "# 📌 Load Feature Names from Training Data (to ensure alignment)\n",
    "trained_feature_names = [\n",
    "    'Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines',\n",
    "    'InterestRate', 'LoanTerm', 'DTIRatio', \"Education_Bachelor's\", 'Education_High School', \n",
    "    \"Education_Master's\", 'Education_PhD', 'EmploymentType_Full-time', 'EmploymentType_Part-time', \n",
    "    'EmploymentType_Self-employed', 'EmploymentType_Unemployed', 'MaritalStatus_Divorced', \n",
    "    'MaritalStatus_Married', 'MaritalStatus_Single', 'HasMortgage_No', 'HasMortgage_Yes', \n",
    "    'HasDependents_No', 'HasDependents_Yes', 'LoanPurpose_Auto', 'LoanPurpose_Business', \n",
    "    'LoanPurpose_Education', 'LoanPurpose_Home', 'LoanPurpose_Other', 'HasCoSigner_No', \n",
    "    'HasCoSigner_Yes', 'Default_False', 'Default_True'\n",
    "]\n",
    "\n",
    "# 📌 Ensure Column Order Matches Training Data (Fill Missing Columns with 0)\n",
    "for col in trained_feature_names:\n",
    "    if col not in processed_loan_sample.columns:\n",
    "        processed_loan_sample[col] = 0  # Assign 0 to missing columns\n",
    "\n",
    "# 📌 Reorder Columns to Match Training Data\n",
    "processed_loan_sample = processed_loan_sample[trained_feature_names]\n",
    "\n",
    "# ----------------- 🔹 FEATURE SCALING 🔹 -----------------\n",
    "# 📌 Apply Scaling (Use the same scaler as in training)\n",
    "scaler = StandardScaler()\n",
    "processed_loan_sample_scaled = scaler.fit_transform(processed_loan_sample)\n",
    "\n",
    "print(\"✅ Feature Scaling Applied!\")\n",
    "\n",
    "# ----------------- 🔹 MODEL PREDICTION 🔹 -----------------\n",
    "# 📌 Make Prediction\n",
    "prediction = loan_model.predict(processed_loan_sample_scaled)\n",
    "loan_status = \"Rejected\" if prediction[0] == 0 else \"Approved\"\n",
    "\n",
    "# 📌 Display Final Prediction\n",
    "print(\"\\n🔴 Model Prediction: Loan is **{}**\".format(loan_status))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d8b81a41-cb7e-48a1-8803-7b664ad9b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoanPurpose_Other: 0.4146\n",
      "CreditScore: 0.1747\n",
      "DTIRatio: 0.1411\n",
      "LoanPurpose_Business: 0.1209\n",
      "LoanPurpose_Home: 0.0829\n",
      "LoanPurpose_Auto: 0.0379\n",
      "LoanPurpose_Education: 0.0251\n",
      "LoanAmount: 0.0030\n",
      "LoanTerm: 0.0000\n",
      "Education_Master's: 0.0000\n",
      "Education_High School: 0.0000\n",
      "Education_Bachelor's: 0.0000\n",
      "Default_True: 0.0000\n",
      "InterestRate: 0.0000\n",
      "NumCreditLines: 0.0000\n",
      "MonthsEmployed: 0.0000\n",
      "EmploymentType_Full-time: 0.0000\n",
      "Income: 0.0000\n",
      "Education_PhD: 0.0000\n",
      "EmploymentType_Unemployed: 0.0000\n",
      "EmploymentType_Part-time: 0.0000\n",
      "EmploymentType_Self-employed: 0.0000\n",
      "Default_False: 0.0000\n",
      "MaritalStatus_Divorced: 0.0000\n",
      "MaritalStatus_Married: 0.0000\n",
      "MaritalStatus_Single: 0.0000\n",
      "HasMortgage_No: 0.0000\n",
      "HasMortgage_Yes: 0.0000\n",
      "HasDependents_No: 0.0000\n",
      "HasDependents_Yes: 0.0000\n",
      "HasCoSigner_No: 0.0000\n",
      "HasCoSigner_Yes: 0.0000\n",
      "Age: 0.0000\n"
     ]
    }
   ],
   "source": [
    "importances = loan_model.feature_importances_\n",
    "features = processed_loan_sample.columns\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for idx in sorted_indices:\n",
    "    print(f\"{features[idx]}: {importances[idx]:.4f}\")\n",
    " # Check if rejected cases are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e79db779-7989-430f-be78-17fbaef688b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(processed_loan_sample_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8ae079eb-8019-4f67-a103-559e88bbbaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: Rejected | Predicted: Approved\n"
     ]
    }
   ],
   "source": [
    "test_case = X_train[y_train == 0].sample(1)  # Pick a known rejected loan\n",
    "prediction = loan_model.predict(test_case)\n",
    "print(\"Expected: Rejected | Predicted:\", \"Rejected\" if prediction[0] == 0 else \"Approved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e1c6e148-c7f4-4b38-b135-013eb9f3f59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval Probability: 0.8267\n",
      "Final Decision: Rejected\n"
     ]
    }
   ],
   "source": [
    "probability = loan_model.predict_proba(processed_loan_sample_scaled)[0][1]  # Get probability of approval\n",
    "\n",
    "threshold = 0.9  # Adjust based on data\n",
    "loan_status = \"Rejected\" if probability < threshold else \"Approved\"\n",
    "\n",
    "print(f\"Approval Probability: {probability:.4f}\")\n",
    "print(f\"Final Decision: {loan_status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc339c-3637-464b-a9b7-71f4bcf85403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
